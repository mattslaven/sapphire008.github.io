{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data = pd.read_csv(\"./data/train.csv\")\n",
    "test_data = pd.read_csv(\"./data/test.csv\")\n",
    "submission_data = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>48df886f9</th>\n",
       "      <th>0deb4b6a8</th>\n",
       "      <th>34b15f335</th>\n",
       "      <th>a8cb14b00</th>\n",
       "      <th>2f0771a37</th>\n",
       "      <th>30347e683</th>\n",
       "      <th>d08d1fbe3</th>\n",
       "      <th>6ee66e115</th>\n",
       "      <th>20aa07010</th>\n",
       "      <th>...</th>\n",
       "      <th>3ecc09859</th>\n",
       "      <th>9281abeea</th>\n",
       "      <th>8675bec0b</th>\n",
       "      <th>3a13ed79a</th>\n",
       "      <th>f677d4d13</th>\n",
       "      <th>71b203550</th>\n",
       "      <th>137efaa80</th>\n",
       "      <th>fb36b89d9</th>\n",
       "      <th>7e293fbaf</th>\n",
       "      <th>9fc776466</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4459.000000</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.944923e+06</td>\n",
       "      <td>1.465493e+04</td>\n",
       "      <td>1.390895e+03</td>\n",
       "      <td>2.672245e+04</td>\n",
       "      <td>4.530164e+03</td>\n",
       "      <td>2.640996e+04</td>\n",
       "      <td>3.070811e+04</td>\n",
       "      <td>1.686522e+04</td>\n",
       "      <td>4.669208e+03</td>\n",
       "      <td>2.569407e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.676057e+05</td>\n",
       "      <td>4.446239e+05</td>\n",
       "      <td>8.056219e+05</td>\n",
       "      <td>7.812966e+05</td>\n",
       "      <td>143.529939</td>\n",
       "      <td>1.213809e+05</td>\n",
       "      <td>3.573451e+04</td>\n",
       "      <td>3.123741e+05</td>\n",
       "      <td>9.219960e+04</td>\n",
       "      <td>2.279100e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.234312e+06</td>\n",
       "      <td>3.893298e+05</td>\n",
       "      <td>6.428302e+04</td>\n",
       "      <td>5.699652e+05</td>\n",
       "      <td>2.359124e+05</td>\n",
       "      <td>1.514730e+06</td>\n",
       "      <td>5.770590e+05</td>\n",
       "      <td>7.512756e+05</td>\n",
       "      <td>1.879449e+05</td>\n",
       "      <td>9.610183e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.068038e+06</td>\n",
       "      <td>4.428889e+06</td>\n",
       "      <td>4.513246e+06</td>\n",
       "      <td>6.839451e+06</td>\n",
       "      <td>9584.318507</td>\n",
       "      <td>4.720709e+06</td>\n",
       "      <td>1.614622e+06</td>\n",
       "      <td>4.318501e+06</td>\n",
       "      <td>1.635993e+06</td>\n",
       "      <td>1.811139e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.260000e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000e+07</td>\n",
       "      <td>2.000000e+07</td>\n",
       "      <td>4.000000e+06</td>\n",
       "      <td>2.000000e+07</td>\n",
       "      <td>1.480000e+07</td>\n",
       "      <td>1.000000e+08</td>\n",
       "      <td>2.070800e+07</td>\n",
       "      <td>4.000000e+07</td>\n",
       "      <td>1.040000e+07</td>\n",
       "      <td>3.196120e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>7.600000e+07</td>\n",
       "      <td>1.235880e+08</td>\n",
       "      <td>1.300000e+08</td>\n",
       "      <td>1.444000e+08</td>\n",
       "      <td>640000.000000</td>\n",
       "      <td>3.013120e+08</td>\n",
       "      <td>1.064200e+08</td>\n",
       "      <td>1.400000e+08</td>\n",
       "      <td>6.176800e+07</td>\n",
       "      <td>4.320000e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 4992 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             target     48df886f9     0deb4b6a8     34b15f335     a8cb14b00  \\\n",
       "count  4.459000e+03  4.459000e+03  4.459000e+03  4.459000e+03  4.459000e+03   \n",
       "mean   5.944923e+06  1.465493e+04  1.390895e+03  2.672245e+04  4.530164e+03   \n",
       "std    8.234312e+06  3.893298e+05  6.428302e+04  5.699652e+05  2.359124e+05   \n",
       "min    3.000000e+04  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    6.000000e+05  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    2.260000e+06  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    8.000000e+06  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max    4.000000e+07  2.000000e+07  4.000000e+06  2.000000e+07  1.480000e+07   \n",
       "\n",
       "          2f0771a37     30347e683     d08d1fbe3     6ee66e115     20aa07010  \\\n",
       "count  4.459000e+03  4.459000e+03  4.459000e+03  4.459000e+03  4.459000e+03   \n",
       "mean   2.640996e+04  3.070811e+04  1.686522e+04  4.669208e+03  2.569407e+06   \n",
       "std    1.514730e+06  5.770590e+05  7.512756e+05  1.879449e+05  9.610183e+06   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  6.000000e+05   \n",
       "max    1.000000e+08  2.070800e+07  4.000000e+07  1.040000e+07  3.196120e+08   \n",
       "\n",
       "           ...          3ecc09859     9281abeea     8675bec0b     3a13ed79a  \\\n",
       "count      ...       4.459000e+03  4.459000e+03  4.459000e+03  4.459000e+03   \n",
       "mean       ...       4.676057e+05  4.446239e+05  8.056219e+05  7.812966e+05   \n",
       "std        ...       4.068038e+06  4.428889e+06  4.513246e+06  6.839451e+06   \n",
       "min        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max        ...       7.600000e+07  1.235880e+08  1.300000e+08  1.444000e+08   \n",
       "\n",
       "           f677d4d13     71b203550     137efaa80     fb36b89d9     7e293fbaf  \\\n",
       "count    4459.000000  4.459000e+03  4.459000e+03  4.459000e+03  4.459000e+03   \n",
       "mean      143.529939  1.213809e+05  3.573451e+04  3.123741e+05  9.219960e+04   \n",
       "std      9584.318507  4.720709e+06  1.614622e+06  4.318501e+06  1.635993e+06   \n",
       "min         0.000000  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%         0.000000  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%         0.000000  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%         0.000000  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max    640000.000000  3.013120e+08  1.064200e+08  1.400000e+08  6.176800e+07   \n",
       "\n",
       "          9fc776466  \n",
       "count  4.459000e+03  \n",
       "mean   2.279100e+05  \n",
       "std    1.811139e+06  \n",
       "min    0.000000e+00  \n",
       "25%    0.000000e+00  \n",
       "50%    0.000000e+00  \n",
       "75%    0.000000e+00  \n",
       "max    4.320000e+07  \n",
       "\n",
       "[8 rows x 4992 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>48df886f9</th>\n",
       "      <th>0deb4b6a8</th>\n",
       "      <th>34b15f335</th>\n",
       "      <th>a8cb14b00</th>\n",
       "      <th>2f0771a37</th>\n",
       "      <th>30347e683</th>\n",
       "      <th>d08d1fbe3</th>\n",
       "      <th>6ee66e115</th>\n",
       "      <th>20aa07010</th>\n",
       "      <th>dc5a8f1d8</th>\n",
       "      <th>...</th>\n",
       "      <th>3ecc09859</th>\n",
       "      <th>9281abeea</th>\n",
       "      <th>8675bec0b</th>\n",
       "      <th>3a13ed79a</th>\n",
       "      <th>f677d4d13</th>\n",
       "      <th>71b203550</th>\n",
       "      <th>137efaa80</th>\n",
       "      <th>fb36b89d9</th>\n",
       "      <th>7e293fbaf</th>\n",
       "      <th>9fc776466</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.934200e+04</td>\n",
       "      <td>4.934200e+04</td>\n",
       "      <td>4.934200e+04</td>\n",
       "      <td>4.934200e+04</td>\n",
       "      <td>4.934200e+04</td>\n",
       "      <td>4.934200e+04</td>\n",
       "      <td>4.934200e+04</td>\n",
       "      <td>4.934200e+04</td>\n",
       "      <td>4.934200e+04</td>\n",
       "      <td>4.934200e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>4.934200e+04</td>\n",
       "      <td>4.934200e+04</td>\n",
       "      <td>4.934200e+04</td>\n",
       "      <td>4.934200e+04</td>\n",
       "      <td>4.934200e+04</td>\n",
       "      <td>4.934200e+04</td>\n",
       "      <td>4.934200e+04</td>\n",
       "      <td>4.934200e+04</td>\n",
       "      <td>4.934200e+04</td>\n",
       "      <td>4.934200e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.773787e+04</td>\n",
       "      <td>6.258726e+04</td>\n",
       "      <td>1.036752e+05</td>\n",
       "      <td>6.289853e+04</td>\n",
       "      <td>6.713354e+04</td>\n",
       "      <td>8.083879e+04</td>\n",
       "      <td>6.181014e+04</td>\n",
       "      <td>5.515752e+04</td>\n",
       "      <td>1.406324e+06</td>\n",
       "      <td>8.128668e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.193910e+05</td>\n",
       "      <td>1.355955e+05</td>\n",
       "      <td>3.242217e+05</td>\n",
       "      <td>1.437856e+05</td>\n",
       "      <td>9.302367e+04</td>\n",
       "      <td>8.047145e+04</td>\n",
       "      <td>6.076865e+04</td>\n",
       "      <td>1.323210e+05</td>\n",
       "      <td>1.675766e+05</td>\n",
       "      <td>1.282487e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.745182e+06</td>\n",
       "      <td>2.322787e+06</td>\n",
       "      <td>2.586951e+06</td>\n",
       "      <td>2.765941e+06</td>\n",
       "      <td>3.206124e+06</td>\n",
       "      <td>2.845031e+06</td>\n",
       "      <td>2.780137e+06</td>\n",
       "      <td>1.923517e+06</td>\n",
       "      <td>6.872366e+06</td>\n",
       "      <td>2.378938e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>3.115190e+06</td>\n",
       "      <td>2.598454e+06</td>\n",
       "      <td>3.782996e+06</td>\n",
       "      <td>3.663374e+06</td>\n",
       "      <td>5.041000e+06</td>\n",
       "      <td>2.100210e+06</td>\n",
       "      <td>2.040655e+06</td>\n",
       "      <td>3.592018e+06</td>\n",
       "      <td>3.761816e+06</td>\n",
       "      <td>2.413798e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.504447e+08</td>\n",
       "      <td>2.283295e+08</td>\n",
       "      <td>2.758171e+08</td>\n",
       "      <td>3.972621e+08</td>\n",
       "      <td>4.667591e+08</td>\n",
       "      <td>2.852223e+08</td>\n",
       "      <td>4.863751e+08</td>\n",
       "      <td>2.043290e+08</td>\n",
       "      <td>3.435658e+08</td>\n",
       "      <td>2.310167e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>5.351692e+08</td>\n",
       "      <td>1.236547e+08</td>\n",
       "      <td>3.793398e+08</td>\n",
       "      <td>4.025480e+08</td>\n",
       "      <td>9.657530e+08</td>\n",
       "      <td>1.680065e+08</td>\n",
       "      <td>2.497913e+08</td>\n",
       "      <td>3.200000e+08</td>\n",
       "      <td>3.186300e+08</td>\n",
       "      <td>2.189782e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 4991 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          48df886f9     0deb4b6a8     34b15f335     a8cb14b00     2f0771a37  \\\n",
       "count  4.934200e+04  4.934200e+04  4.934200e+04  4.934200e+04  4.934200e+04   \n",
       "mean   5.773787e+04  6.258726e+04  1.036752e+05  6.289853e+04  6.713354e+04   \n",
       "std    1.745182e+06  2.322787e+06  2.586951e+06  2.765941e+06  3.206124e+06   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max    1.504447e+08  2.283295e+08  2.758171e+08  3.972621e+08  4.667591e+08   \n",
       "\n",
       "          30347e683     d08d1fbe3     6ee66e115     20aa07010     dc5a8f1d8  \\\n",
       "count  4.934200e+04  4.934200e+04  4.934200e+04  4.934200e+04  4.934200e+04   \n",
       "mean   8.083879e+04  6.181014e+04  5.515752e+04  1.406324e+06  8.128668e+04   \n",
       "std    2.845031e+06  2.780137e+06  1.923517e+06  6.872366e+06  2.378938e+06   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max    2.852223e+08  4.863751e+08  2.043290e+08  3.435658e+08  2.310167e+08   \n",
       "\n",
       "           ...          3ecc09859     9281abeea     8675bec0b     3a13ed79a  \\\n",
       "count      ...       4.934200e+04  4.934200e+04  4.934200e+04  4.934200e+04   \n",
       "mean       ...       1.193910e+05  1.355955e+05  3.242217e+05  1.437856e+05   \n",
       "std        ...       3.115190e+06  2.598454e+06  3.782996e+06  3.663374e+06   \n",
       "min        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max        ...       5.351692e+08  1.236547e+08  3.793398e+08  4.025480e+08   \n",
       "\n",
       "          f677d4d13     71b203550     137efaa80     fb36b89d9     7e293fbaf  \\\n",
       "count  4.934200e+04  4.934200e+04  4.934200e+04  4.934200e+04  4.934200e+04   \n",
       "mean   9.302367e+04  8.047145e+04  6.076865e+04  1.323210e+05  1.675766e+05   \n",
       "std    5.041000e+06  2.100210e+06  2.040655e+06  3.592018e+06  3.761816e+06   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max    9.657530e+08  1.680065e+08  2.497913e+08  3.200000e+08  3.186300e+08   \n",
       "\n",
       "          9fc776466  \n",
       "count  4.934200e+04  \n",
       "mean   1.282487e+05  \n",
       "std    2.413798e+06  \n",
       "min    0.000000e+00  \n",
       "25%    0.000000e+00  \n",
       "50%    0.000000e+00  \n",
       "75%    0.000000e+00  \n",
       "max    2.189782e+08  \n",
       "\n",
       "[8 rows x 4991 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>48df886f9</th>\n",
       "      <th>0deb4b6a8</th>\n",
       "      <th>34b15f335</th>\n",
       "      <th>a8cb14b00</th>\n",
       "      <th>2f0771a37</th>\n",
       "      <th>30347e683</th>\n",
       "      <th>d08d1fbe3</th>\n",
       "      <th>6ee66e115</th>\n",
       "      <th>...</th>\n",
       "      <th>3ecc09859</th>\n",
       "      <th>9281abeea</th>\n",
       "      <th>8675bec0b</th>\n",
       "      <th>3a13ed79a</th>\n",
       "      <th>f677d4d13</th>\n",
       "      <th>71b203550</th>\n",
       "      <th>137efaa80</th>\n",
       "      <th>fb36b89d9</th>\n",
       "      <th>7e293fbaf</th>\n",
       "      <th>9fc776466</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d6aaf2</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fbd867</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0027d6b71</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0028cbf45</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002a68644</td>\n",
       "      <td>14400000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4993 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID      target  48df886f9  0deb4b6a8  34b15f335  a8cb14b00  \\\n",
       "0  000d6aaf2  38000000.0        0.0          0        0.0          0   \n",
       "1  000fbd867    600000.0        0.0          0        0.0          0   \n",
       "2  0027d6b71  10000000.0        0.0          0        0.0          0   \n",
       "3  0028cbf45   2000000.0        0.0          0        0.0          0   \n",
       "4  002a68644  14400000.0        0.0          0        0.0          0   \n",
       "\n",
       "   2f0771a37  30347e683  d08d1fbe3  6ee66e115    ...      3ecc09859  \\\n",
       "0          0          0          0          0    ...            0.0   \n",
       "1          0          0          0          0    ...            0.0   \n",
       "2          0          0          0          0    ...            0.0   \n",
       "3          0          0          0          0    ...            0.0   \n",
       "4          0          0          0          0    ...            0.0   \n",
       "\n",
       "   9281abeea  8675bec0b  3a13ed79a  f677d4d13  71b203550  137efaa80  \\\n",
       "0        0.0        0.0          0          0          0          0   \n",
       "1        0.0        0.0          0          0          0          0   \n",
       "2        0.0        0.0          0          0          0          0   \n",
       "3        0.0        0.0          0          0          0          0   \n",
       "4        0.0        0.0          0          0          0          0   \n",
       "\n",
       "   fb36b89d9  7e293fbaf  9fc776466  \n",
       "0          0          0          0  \n",
       "1          0          0          0  \n",
       "2          0          0          0  \n",
       "3          0          0          0  \n",
       "4          0          0          0  \n",
       "\n",
       "[5 rows x 4993 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(np.isnan(train_data.isnull().sum().values))\n",
    "\n",
    "# No missing values in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(np.isnan(test_data.isnull().sum().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there are so many parameters, let's use XGBoost to select features\n",
    "X = train_data.iloc[:, 2:].values\n",
    "y = train_data['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4459, 4991)\n",
      "(4459,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y)\n",
    "plt.gcf().set_size_inches(12, 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBRegressor()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSLE(y_predict, y_test):\n",
    "    \"\"\"Evaluation metric Root Mean Squared Logarithmic Error\"\"\"\n",
    "    return np.sqrt(np.nanmean((np.log(y_predict+1) - np.log(y_test+1))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8393296647239583\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(X)\n",
    "print(RMSLE(y_predict, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_important_features(feature_importances, tol=1E-6):\n",
    "    # filter out features that has minimal importance\n",
    "    important_feature_ind = np.where(feature_importances > 1E-6)[0]\n",
    "    important_features = model.feature_importances_[important_feature_ind]\n",
    "    sorted_important_feature_ind = np.array([x for _,x in sorted(\n",
    "                    zip(important_features,important_feature_ind))])[::-1]\n",
    "    return sorted_important_feature_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_important_feature_ind = extract_important_features(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_important_feature_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03448276, 0.02758621, 0.01896552, 0.01896552, 0.01724138,\n",
       "       0.0137931 , 0.0137931 , 0.01206897, 0.01206897, 0.01206897,\n",
       "       0.01034483, 0.01034483, 0.01034483, 0.01034483, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "       0.00862069, 0.00862069, 0.00689655, 0.00689655, 0.00689655,\n",
       "       0.00689655, 0.00689655, 0.00689655, 0.00689655, 0.00689655,\n",
       "       0.00689655, 0.00689655, 0.00689655, 0.00689655, 0.00689655,\n",
       "       0.00689655, 0.00517241, 0.00517241, 0.00517241, 0.00517241,\n",
       "       0.00517241, 0.00517241, 0.00517241, 0.00517241, 0.00517241,\n",
       "       0.00517241, 0.00517241, 0.00517241, 0.00517241, 0.00517241,\n",
       "       0.00517241, 0.00517241, 0.00517241, 0.00517241, 0.00517241,\n",
       "       0.00517241, 0.00517241, 0.00517241, 0.00517241, 0.00517241,\n",
       "       0.00517241, 0.00517241, 0.00517241, 0.00517241, 0.00517241,\n",
       "       0.00517241, 0.00517241, 0.00517241, 0.00344828, 0.00344828,\n",
       "       0.00344828, 0.00344828, 0.00344828, 0.00344828, 0.00344828,\n",
       "       0.00344828, 0.00344828, 0.00344828, 0.00344828, 0.00344828,\n",
       "       0.00344828, 0.00344828, 0.00344828, 0.00344828, 0.00344828,\n",
       "       0.00344828, 0.00344828, 0.00344828, 0.00344828, 0.00344828,\n",
       "       0.00344828, 0.00344828, 0.00344828, 0.00344828, 0.00344828,\n",
       "       0.00344828, 0.00344828, 0.00344828, 0.00344828, 0.00344828,\n",
       "       0.00344828, 0.00344828, 0.00344828, 0.00344828, 0.00344828,\n",
       "       0.00344828, 0.00344828, 0.00344828, 0.00344828, 0.00344828,\n",
       "       0.00344828, 0.00344828, 0.00344828, 0.00344828, 0.00344828,\n",
       "       0.00344828, 0.00344828, 0.00344828, 0.00344828, 0.00344828,\n",
       "       0.00344828, 0.00344828, 0.00344828, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414, 0.00172414, 0.00172414, 0.00172414,\n",
       "       0.00172414, 0.00172414], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_[sorted_important_feature_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with simple XGBoost and RandomForest using the important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8809839111057105\n",
      "1.8483280111644638\n",
      "1.881242016749642\n",
      "1.9396014034429652\n",
      "1.9274425890035274\n",
      "1.8658012261166985\n",
      "1.8866572076949215\n",
      "1.8630890970897818\n",
      "1.8624094329275218\n",
      "1.8569099930555\n"
     ]
    }
   ],
   "source": [
    "model_xgb = XGBRegressor()\n",
    "for rs in range(30, 40):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[:, sorted_important_feature_ind],\n",
    "                                                        y, test_size=0.2, random_state=rs)\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    y_predict = model_xgb.predict(X_test)\n",
    "    print(RMSLE(y_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 1.879653783075668 , with  272 features\n",
      "1 : 1.8738600296682244 , with  158 features\n",
      "2 : 1.8742622487559337 , with  153 features\n",
      "3 : 1.8739001845143464 , with  153 features\n",
      "4 : 1.87413516508366 , with  153 features\n",
      "5 : 1.8738438205473869 , with  153 features\n",
      "6 : 1.874271821477142 , with  153 features\n",
      "7 : 1.8739384327796984 , with  153 features\n",
      "8 : 1.8743543756941254 , with  152 features\n",
      "9 : 1.8739778846146096 , with  152 features\n",
      "[4881  733 3927  808 4872  401 1791  916 1140 4949 1675 4855 3686 3890\n",
      " 4434 3771 4660 4528 2221 2232 3311 3702 4981   31 4066 3660 4554 1427\n",
      " 3711 2721 2364 2656 4802  925 1948  898  168 2882 1530 3706 3672  964\n",
      " 4243 3217 1097 2193  493  878 3088 4916 1358 2185 2875 3979  920  562\n",
      " 4204 2500 1057 1142 4408 3836 4167 4101 3866 2424 1556 1447  693  303\n",
      "  118 4696 4581 3826 3742 3413 3216 2719 2695 2477 2237 1729 1325  655\n",
      " 4939 4758 4629 4494 4330 4268 4228 4021 3992 3928 3856 3735 3553 3514\n",
      " 3378 3189 2984 2662 2552 2292 2161 1605 1486  435   17 4720 3800 1052\n",
      "  108 4808  594 1935 3664 4274 4414  572 2995  908  355 3508 4098 1564\n",
      " 1781  658  550  602 1224 1942 2835 3939   53 2598  306  705 3994 4507\n",
      "    8 1571 4358 3570 3724 1653 2755 3592 3323 1614 1742 1044]\n"
     ]
    }
   ],
   "source": [
    "# XGBoost with multiple iterations\n",
    "num_iter = 10\n",
    "index = sorted_important_feature_ind\n",
    "models_xgboost = [[]]*num_iter\n",
    "for i in range(num_iter):\n",
    "    models_xgboost[i] = XGBRegressor()\n",
    "    rmsle_val = []\n",
    "    for rs in range(30, 50):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X[:, index],\n",
    "                                                            y, test_size=0.2, random_state=rs)\n",
    "        models_xgboost[i].fit(X_train, y_train)\n",
    "        y_predict = models_xgboost[i].predict(X_test)\n",
    "        rmsle_val.append(RMSLE(y_predict, y_test))\n",
    "    print(i, ':', np.mean(rmsle_val), ', with ', len(index), 'features')\n",
    "    # Look at important features leftover\n",
    "    temp_index = extract_important_features(models_xgboost[i].feature_importances_)\n",
    "    index = index[temp_index] # iteratively updating the features leftover\n",
    "print(np.array(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "np.savez('./data/good_feature_indices.npz', index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(X[:, index].std(axis=0)>10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:1.02196e+07\tvalid-rmse:9.74635e+06\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 30 rounds.\n",
      "[100]\ttrain-rmse:7.91576e+06\tvalid-rmse:8.17766e+06\n",
      "[200]\ttrain-rmse:6.56827e+06\tvalid-rmse:7.44525e+06\n",
      "[300]\ttrain-rmse:5.74311e+06\tvalid-rmse:7.12225e+06\n",
      "[400]\ttrain-rmse:5.19471e+06\tvalid-rmse:6.98255e+06\n",
      "[500]\ttrain-rmse:4.8035e+06\tvalid-rmse:6.91851e+06\n",
      "[600]\ttrain-rmse:4.51141e+06\tvalid-rmse:6.89654e+06\n",
      "[700]\ttrain-rmse:4.27312e+06\tvalid-rmse:6.87879e+06\n",
      "[800]\ttrain-rmse:4.08279e+06\tvalid-rmse:6.86502e+06\n",
      "[900]\ttrain-rmse:3.92134e+06\tvalid-rmse:6.85755e+06\n",
      "[1000]\ttrain-rmse:3.78599e+06\tvalid-rmse:6.85299e+06\n",
      "Stopping. Best iteration:\n",
      "[1001]\ttrain-rmse:3.78421e+06\tvalid-rmse:6.85291e+06\n",
      "\n",
      "1.8350776254166632\n"
     ]
    }
   ],
   "source": [
    "# Properly train the XGBoost\n",
    "import xgboost as xgb\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[:, index],\n",
    "                                                        y, test_size=0.2, random_state=rs)\n",
    "params = {'objective': 'reg:linear', \n",
    "          'eval_metric': 'rmse',\n",
    "          'eta': 0.005,\n",
    "          'max_depth': 15, \n",
    "          'subsample': 0.7, \n",
    "          'colsample_bytree': 0.5,\n",
    "          'alpha':0,\n",
    "          'random_state': 42, \n",
    "          'silent': True}\n",
    "xgtrain = xgb.DMatrix(X_train, y_train)\n",
    "xgvals = xgb.DMatrix(X_test, y_test)\n",
    "watchlist = [(xgtrain, 'train'), (xgvals, 'valid')]\n",
    "model_xgb = xgb.train(params, xgtrain, 5000, watchlist, maximize=False,\n",
    "                early_stopping_rounds=30, verbose_eval=100)\n",
    "y_predict = model_xgb.predict(xgb.DMatrix(X_test), ntree_limit=model_xgb.best_ntree_limit)\n",
    "print(RMSLE(y_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7094329194641205\n",
      "1.7522741420919987\n",
      "1.6933996598001222\n",
      "1.6998235178998526\n",
      "1.7675607282881904\n",
      "1.722015348543114\n",
      "1.7097789463192337\n",
      "1.6880881139813322\n",
      "1.7214386789183165\n",
      "1.7032671527531487\n",
      "1.7342282381291443\n",
      "1.6786444480156406\n",
      "1.729162794140566\n",
      "1.773401796259706\n",
      "1.6631786944228732\n",
      "1.6429815660539353\n",
      "1.6843935172942497\n",
      "1.6820915907398473\n",
      "1.7529989029777104\n",
      "1.8052003311433578\n"
     ]
    }
   ],
   "source": [
    "# RandomForest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model_rf = RandomForestRegressor()\n",
    "for rs in range(30, 50):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[:, index],\n",
    "                                                        y, test_size=0.2, random_state=rs)\n",
    "    model_rf.fit(X_train, y_train)\n",
    "    y_predict = model_rf.predict(X_test)\n",
    "    print(RMSLE(y_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's rmse: 7.58464e+06\n",
      "[100]\tvalid_0's rmse: 7.38148e+06\n",
      "[150]\tvalid_0's rmse: 7.22995e+06\n",
      "[200]\tvalid_0's rmse: 7.12488e+06\n",
      "[250]\tvalid_0's rmse: 7.04591e+06\n",
      "[300]\tvalid_0's rmse: 6.99291e+06\n",
      "[350]\tvalid_0's rmse: 6.95134e+06\n",
      "[400]\tvalid_0's rmse: 6.91854e+06\n",
      "[450]\tvalid_0's rmse: 6.89377e+06\n",
      "[500]\tvalid_0's rmse: 6.87643e+06\n",
      "[550]\tvalid_0's rmse: 6.86276e+06\n",
      "[600]\tvalid_0's rmse: 6.84935e+06\n",
      "[650]\tvalid_0's rmse: 6.83984e+06\n",
      "[700]\tvalid_0's rmse: 6.83347e+06\n",
      "[750]\tvalid_0's rmse: 6.82647e+06\n",
      "[800]\tvalid_0's rmse: 6.82324e+06\n",
      "[850]\tvalid_0's rmse: 6.82004e+06\n",
      "[900]\tvalid_0's rmse: 6.81528e+06\n",
      "[950]\tvalid_0's rmse: 6.8138e+06\n",
      "[1000]\tvalid_0's rmse: 6.81035e+06\n",
      "[1050]\tvalid_0's rmse: 6.80922e+06\n",
      "[1100]\tvalid_0's rmse: 6.80835e+06\n",
      "[1150]\tvalid_0's rmse: 6.80727e+06\n",
      "[1200]\tvalid_0's rmse: 6.80699e+06\n",
      "[1250]\tvalid_0's rmse: 6.80589e+06\n",
      "[1300]\tvalid_0's rmse: 6.80644e+06\n",
      "[1350]\tvalid_0's rmse: 6.8065e+06\n",
      "Early stopping, best iteration is:\n",
      "[1279]\tvalid_0's rmse: 6.80535e+06\n",
      "1.8045660073299785\n"
     ]
    }
   ],
   "source": [
    "# Light GBM\n",
    "import lightgbm as lgbm\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[:, index],\n",
    "                                                        y, test_size=0.2, random_state=rs)\n",
    "params = {\n",
    "        \"objective\" : \"regression\",\n",
    "        \"metric\" : \"rmse\",\n",
    "        \"num_leaves\" : 35,\n",
    "        \"learning_rate\" : 0.005,\n",
    "        \"bagging_fraction\" : 0.7,\n",
    "        \"feature_fraction\" : 0.5,\n",
    "        \"bagging_frequency\" : 5,\n",
    "        \"bagging_seed\" : 42,\n",
    "        \"verbosity\" : -1,\n",
    "        \"random_seed\": 42\n",
    "    }\n",
    "lgtrain = lgb.Dataset(X_train, label=y_train)\n",
    "lgvals = lgb.Dataset(X_test, label=y_test)\n",
    "model_lgbm = lgbm.train(params, lgtrain, 5000, valid_sets=[lgvals],\n",
    "                early_stopping_rounds=100, verbose_eval=50, evals_result={})\n",
    "y_predict = model_lgbm.predict(X_test, num_iteration=model_lgbm.best_iteration)\n",
    "print(RMSLE(y_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8228209376354063\n"
     ]
    }
   ],
   "source": [
    "def combine_models(model_lgbm, model_xgb, model_rf, X_submit):\n",
    "    y_predict_lgbm = model_lgbm.predict(X_submit, num_iteration=model_lgbm.best_iteration)\n",
    "    y_predict_xgb =  model_xgb.predict(xgb.DMatrix(X_submit), ntree_limit=model_xgb.best_ntree_limit)\n",
    "    y_predict_rnf = model_rf.predict(X_submit)\n",
    "    y_predict = np.c_[y_predict_lgbm, y_predict_xgb, y_predict_rnf]\n",
    "    y_predict_mean = np.average(y_predict, axis=1, weights=\n",
    "                            [1./1.8045660073299785,1./1.8350776254166632, 1./1.8052003311433578])\n",
    "    \n",
    "    return y_predict_mean\n",
    "\n",
    "y_predict_all = combine_models(model_lgbm, model_xgb, model_rf, X_test)\n",
    "y_predict_all[y_predict_all<0] = np.nanmean(y_predict_all[y_predict_all>0])\n",
    "print(RMSLE(y_predict_all, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[153 167 247 459 623 678]\n",
      "-43615.47158482677\n"
     ]
    }
   ],
   "source": [
    "print(np.where(y_predict_all<0)[0])\n",
    "print(y_predict_all[153])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First round of submission: Take a weighted average of the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_submit = test_data.iloc[:, 1:].iloc[:, index].values\n",
    "y_predict_submit = combine_models(model_lgbm, model_xgb, model_rf, X_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick and dirty, get rid of the predicted negative values for submission purpose. \n",
    "# Need to further improve model\n",
    "y_predict_submit[y_predict_submit<0] = np.nanmean(y_predict_submit[y_predict_submit>0])\n",
    "submission_data['target'] = y_predict_submit\n",
    "submission_data.to_csv('./data/first_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[:, index], y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def RMSLE_tf(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean((tf.log(y_pred+1) - tf.log(y_true+1))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(32, input_shape=(152,), kernel_initializer=\"random_uniform\"), # input layer\n",
    "    BatchNormalization(), # batch normalization\n",
    "    Activation('relu'),\n",
    "    Dense(100, kernel_initializer=\"random_uniform\", W_regularizer=l2(0.01), \n",
    "         activity_regularizer=l2(0.01)), # hidden layer 1 with 100 neurons\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dense(300, kernel_initializer=\"random_uniform\", W_regularizer=l2(0.01),\n",
    "         activity_regularizer=l2(0.01)), # hidden layer 2 with 300 neurons\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dense(100, kernel_initializer=\"random_uniform\", W_regularizer=l2(0.01),\n",
    "         activity_regularizer=l2(0.01)), # hidden layer 3 with 100 neurons\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dense(1, kernel_initializer=\"random_uniform\"), # output layer with 1 neurons\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss=RMSLE_tf)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=50)\n",
    "\n",
    "model.evaluate(X_test, y_test, batch_size=10) # [loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "\n",
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    \"\"\"Based on https://www.kaggle.com/alexpengxiao/preprocessing-model-averaging-by-xgb-lgb-1-39\"\"\"\n",
    "    def __init__(self, models, weights=None):\n",
    "        self.models = models\n",
    "        self.weigths = weights\n",
    "    \n",
    "    # we define clones of the original models to fit the data in\n",
    "    # the reason of clone is avoiding affect the original base models\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]  \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([ model.predict(X) for model in self.models_ ])\n",
    "        if self.weights is None:\n",
    "            return np.mean(predictions, axis=1)\n",
    "        else:\n",
    "            return np.average(predictions, axis=1, weights=self.weights)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
